# import os
# import sys
# import pandas as pd
# import asyncio
# import httpx
# import time
# from openai import AsyncOpenAI, APIConnectionError, RateLimitError, APITimeoutError
# from tqdm.asyncio import tqdm_asyncio
# from concurrent.futures import ThreadPoolExecutor

# # ================= 1. å¯¼å…¥æœ¬åœ°è¯„æµ‹æ¨¡å— =================
# JUDGE_PATH = "/data/home/the/rxliu/projects/open-r1-main/tests/utils"
# if JUDGE_PATH not in sys.path:
#     sys.path.append(JUDGE_PATH)

# try:
#     from llm_judge import llm_judge_via_api
#     print("æˆåŠŸå¯¼å…¥ llm_judge_via_api")
# except ImportError:
#     print(f"ã€é”™è¯¯ã€‘æ— æ³•ä» {JUDGE_PATH} å¯¼å…¥ llm_judge_via_api")
#     exit(1)

# # ================= 2. é…ç½®åŒºåŸŸ =================
# INPUT_FILE = "/ssd5/rxliu/datasets/rcmu/sampled_math_data.parquet"
# OUTPUT_BASE = INPUT_FILE.replace(".parquet", "_qwen3-max-preview_results")

# # ç”Ÿæˆæ¨¡å‹é…ç½®
# GEN_API_KEY = "sk-8d445207b1ab47efb83069ccc1b845b6"
# GEN_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
# GEN_MODEL_NAME = "qwen3-max-preview"

# # è¯„æµ‹æ¨¡å‹é…ç½®
# JUDGE_API_KEY = GEN_API_KEY 
# JUDGE_API_URL = GEN_BASE_URL 
# JUDGE_MODEL_NAME = "qwen3-next-80b-a3b-instruct"

# # --- æ€§èƒ½å‚æ•° ---
# MAX_ATTEMPTS = 1

# # ã€å¹¶å‘ 200ã€‘æ—¢ç„¶å®æµ‹æ²¡é—®é¢˜ï¼Œå°±ä¿æŒé«˜å¹¶å‘
# MAX_CONCURRENCY = 200

# # ã€æœ€å¤§è¾“å‡ºã€‘
# MAX_TOKENS = 32768
# # MAX_TOKENS = 65536

# # ã€è¶…æ—¶ 20åˆ†é’Ÿã€‘é˜²æ­¢é•¿æ€è€ƒå› ä¸ºç½‘ç»œæ³¢åŠ¨æ–­è¿
# REQUEST_TIMEOUT = 1200.0
# # ===========================================

# judge_executor = ThreadPoolExecutor(max_workers=32) # ç¨å¾®è°ƒå¤§ä¸€ç‚¹åˆ¤é¢˜çº¿ç¨‹æ± 

# def extract_last_boxed_content(text):
#     """
#     æå– \boxed{...}ã€‚å¦‚æœå¤±è´¥è¿”å› Noneã€‚
#     """
#     if not text: return None
#     idx = text.rfind("\\boxed{")
#     if idx == -1:
#         return None 

#     content_start = idx + 7 
#     balance = 0
#     content_end = -1
    
#     for i in range(content_start, len(text)):
#         char = text[i]
#         if char == '{':
#             balance += 1
#         elif char == '}':
#             if balance == 0:
#                 content_end = i
#                 break
#             balance -= 1
            
#     if content_end != -1:
#         return text[content_start:content_end]
#     return None

# def run_judge_sync(predicted, ground_truth):
#     """åŒæ­¥è¯„æµ‹å‡½æ•°"""
#     try:
#         if not predicted: return False
#         is_correct = llm_judge_via_api(
#             predicted, 
#             ground_truth, 
#             JUDGE_API_URL, 
#             JUDGE_API_KEY, 
#             JUDGE_MODEL_NAME
#         )
#         return is_correct
#     except Exception as e:
#         # print(f"Judge Error: {e}") 
#         return False



# async def get_qwen_response_async(client, prompt):
#     messages = [{"role": "user", "content": prompt}]
    
#     try:
#         response = await client.chat.completions.create(
#             model=GEN_MODEL_NAME,
#             messages=messages,
#             extra_body={"enable_thinking": True},
#             stream=False, # å…³æµå¼ï¼Œæé€Ÿç¨³å¥
#             max_tokens=MAX_TOKENS 
#         )
#         print(response)

#         choice = response.choices[0]
        
#         # å³ä½¿è®¾äº†63kï¼Œå¦‚æœè¿˜ä¸å¤Ÿï¼Œä¾ç„¶è¦æŠ¥é”™é‡è¯•
#         if choice.finish_reason == "length":
#             return "", "", "LENGTH_EXCEEDED"

#         message = choice.message
#         answer = message.content if message.content else ""

        
#         reasoning = ""
#         if hasattr(message, "reasoning_content") and message.reasoning_content:
#             reasoning = message.reasoning_content
#         elif hasattr(message, "model_extra") and message.model_extra:
#              reasoning = message.model_extra.get("reasoning_content", "")
                
#         return reasoning, answer, None

#     except RateLimitError:
#         print("Rate limit error encountered.")
#         return "", "", "RATE_LIMIT"
#     except APIConnectionError:
#         print("API connection error encountered.")
#         return "", "", "CONNECTION_ERROR"
#     except APITimeoutError:
#         print("API timeout error encountered.")
#         return "", "", "TIMEOUT"
#     except Exception as e:
#         print(f"Unexpected error: {e}")
#         return "", "", f"Error: {str(e)}"

# async def process_single_problem(sem, client, idx, row):
#     async with sem:
#         problem_text = row['problem']
#         ground_truth = row['answer']
#         problem_results = []

#         for attempt in range(1, MAX_ATTEMPTS + 1):
#             retry_wait = 2
            
#             # --- API ç”Ÿæˆ ---
#             while True:
#                 reasoning, answer, error = await get_qwen_response_async(client, problem_text)
                
#                 if error == "RATE_LIMIT":
#                     await asyncio.sleep(retry_wait)
#                     retry_wait = min(retry_wait * 2, 60)
#                     continue
#                 elif error in ["CONNECTION_ERROR", "TIMEOUT"]:
#                     await asyncio.sleep(5)
#                     continue
#                 elif error:
#                     reasoning = f"[API Error] {error}"
#                     break
#                 else:
#                     break 

#             # --- åˆ¤é¢˜å‡†å¤‡ ---
#             judge_input = None
#             extracted_boxed = None
#             judge_type = "fail"
            
#             if not error:
#                 extracted_boxed = extract_last_boxed_content(answer)
                
#                 # ã€ç­–ç•¥ã€‘ä¼˜å…ˆ Boxedï¼Œæ²¡æœ‰åˆ™å…¨æ–‡
#                 if extracted_boxed:
#                     judge_input = extracted_boxed
#                     judge_type = "boxed"
#                 else:
#                     judge_input = answer 
#                     judge_type = "full_text"
            
#             # --- æ‰§è¡Œåˆ¤é¢˜ ---
#             if judge_input:
#                 loop = asyncio.get_running_loop()
#                 is_correct = await loop.run_in_executor(
#                     judge_executor, 
#                     run_judge_sync, 
#                     judge_input,
#                     ground_truth
#                 )
#             else:
#                 is_correct = False

#             record = {
#                 "id": idx,
#                 "problem": problem_text,
#                 "ground_truth": ground_truth,
#                 "attempt": attempt,
#                 "qwen_reasoning": reasoning,
#                 "qwen_answer": answer,
#                 "extracted_boxed": extracted_boxed, 
#                 "judge_input_type": judge_type,
#                 "is_correct": is_correct
#             }
#             problem_results.append(record)

#             if is_correct:
#                 break
        
#         return problem_results

# async def main():
#     # è°ƒæ•´è¿æ¥æ± ä»¥æ”¯æŒ 200+ å¹¶å‘
#     limits = httpx.Limits(max_keepalive_connections=MAX_CONCURRENCY + 50, max_connections=MAX_CONCURRENCY + 100)
#     http_client = httpx.AsyncClient(limits=limits, timeout=REQUEST_TIMEOUT)
    
#     client = AsyncOpenAI(api_key=GEN_API_KEY, base_url=GEN_BASE_URL, http_client=http_client)


#     print(f"è¯»å–æ–‡ä»¶: {INPUT_FILE}...")
#     try:
#         df = pd.read_parquet(INPUT_FILE)
#         print(f"æˆåŠŸåŠ è½½ï¼Œå…± {len(df)} æ¡æ•°æ®ã€‚")
#     except Exception as e:
#         print(f"è¯»å–å¤±è´¥: {e}")
#         return

#     sem = asyncio.Semaphore(MAX_CONCURRENCY)
    
#     print("="*60)
#     print(f"ğŸš€ å…¨é€Ÿå¯åŠ¨ | å¹¶å‘: {MAX_CONCURRENCY} | MaxTokens: {MAX_TOKENS}")
#     print(f"æ¨¡å¼: éæµå¼ + æœ¬åœ°LLM Judge (ä¼˜å…ˆBoxed -> é™çº§FullText)")
#     print("="*60)

#     tasks = [process_single_problem(sem, client, idx, row) for idx, row in df.iterrows()]
    
#     start_time = time.time()
#     results_nested = await tqdm_asyncio.gather(*tasks)
#     all_results = [item for sublist in results_nested for item in sublist]
#     elapsed = time.time() - start_time

#     if not all_results: return
    
#     # ä¿å­˜ç»“æœ
#     df_res = pd.DataFrame(all_results).sort_values(by=['id', 'attempt'])
    
#     print(f"æ­£åœ¨ä¿å­˜ ({len(df_res)}æ¡è®°å½•)...")
#     df_res.to_excel(OUTPUT_BASE + "_all.xlsx", index=False)
    
#     df_correct = df_res[df_res['is_correct'] == True]
#     df_correct.to_excel(OUTPUT_BASE + "_correct.xlsx", index=False)
    
#     # æœ€ç»ˆç»Ÿè®¡
#     uniq_correct = len(df_correct['id'].unique())
#     print("-" * 30)
#     print(f"è€—æ—¶: {elapsed:.1f}s | åå: {len(df)/elapsed:.2f} TPS")
#     print(f"å‡†ç¡®ç‡: {uniq_correct}/{len(df)} ({uniq_correct/len(df):.2%})")

#     await http_client.aclose()
#     judge_executor.shutdown()

# if __name__ == "__main__":
#     try:
#         import uvloop
#         uvloop.install()
#     except: pass
#     asyncio.run(main())


import os
import sys
import pandas as pd
import asyncio
import httpx
import time
from openai import AsyncOpenAI, APIConnectionError, RateLimitError, APITimeoutError
from tqdm.asyncio import tqdm_asyncio
from concurrent.futures import ThreadPoolExecutor

# ================= 1. å¯¼å…¥æœ¬åœ°è¯„æµ‹æ¨¡å— =================
JUDGE_PATH = "/data/home/the/rxliu/projects/open-r1-main/tests/utils"
if JUDGE_PATH not in sys.path:
    sys.path.append(JUDGE_PATH)

try:
    from llm_judge import llm_judge_via_api
    print("æˆåŠŸå¯¼å…¥ llm_judge_via_api")
except ImportError:
    print(f"ã€é”™è¯¯ã€‘æ— æ³•ä» {JUDGE_PATH} å¯¼å…¥ llm_judge_via_api")
    exit(1)

# ================= 2. é…ç½®åŒºåŸŸ =================
INPUT_FILE = "/ssd5/rxliu/datasets/rcmu/sampled_math_data.parquet"
OUTPUT_BASE = INPUT_FILE.replace(".parquet", "_qwen3-max-preview_results")

# ç”Ÿæˆæ¨¡å‹é…ç½®
GEN_API_KEY = "sk-8d445207b1ab47efb83069ccc1b845b6"
GEN_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
GEN_MODEL_NAME = "qwen3-max-preview"

# è¯„æµ‹æ¨¡å‹é…ç½®
JUDGE_API_KEY = GEN_API_KEY 
JUDGE_API_URL = GEN_BASE_URL 
JUDGE_MODEL_NAME = "qwen3-next-80b-a3b-instruct"

# --- æ€§èƒ½å‚æ•° ---
MAX_ATTEMPTS = 1
MAX_CONCURRENCY = 200
MAX_TOKENS = 32768
THINKING_BUDGET = 81920  # æ€è€ƒé¢„ç®—
REQUEST_TIMEOUT = 1200.0
# ===========================================

judge_executor = ThreadPoolExecutor(max_workers=32) # ç¨å¾®è°ƒå¤§ä¸€ç‚¹åˆ¤é¢˜çº¿ç¨‹æ± 

def extract_last_boxed_content(text):
    """
    æå– \boxed{...}ã€‚å¦‚æœå¤±è´¥è¿”å› Noneã€‚
    """
    if not text: return None
    idx = text.rfind("\\boxed{")
    if idx == -1:
        return None 

    content_start = idx + 7 
    balance = 0
    content_end = -1
    
    for i in range(content_start, len(text)):
        char = text[i]
        if char == '{':
            balance += 1
        elif char == '}':
            if balance == 0:
                content_end = i
                break
            balance -= 1
            
    if content_end != -1:
        return text[content_start:content_end]
    return None

def run_judge_sync(predicted, ground_truth):
    """åŒæ­¥è¯„æµ‹å‡½æ•°"""
    try:
        if not predicted: return False
        is_correct = llm_judge_via_api(
            predicted, 
            ground_truth, 
            JUDGE_API_URL, 
            JUDGE_API_KEY, 
            JUDGE_MODEL_NAME
        )
        return is_correct
    except Exception as e:
        # print(f"Judge Error: {e}") 
        return False

async def get_qwen_response_async(client, prompt):
    """æµå¼è·å–Qwenå“åº”ï¼Œæ”¯æŒæ€è€ƒè¿‡ç¨‹"""
    messages = [{"role": "user", "content": prompt}]
    
    try:
        # å¯ç”¨æµå¼è°ƒç”¨
        response = await client.chat.completions.create(
            model=GEN_MODEL_NAME,
            messages=messages,
            extra_body={
                "enable_thinking": True,
                "thinking_budget": THINKING_BUDGET
            },
            stream=True,  # å¯ç”¨æµå¼
            stream_options={
                "include_usage": True
            },
            max_tokens=MAX_TOKENS
        )
        
        reasoning_content = ""  # å®Œæ•´æ€è€ƒè¿‡ç¨‹
        answer_content = ""     # å®Œæ•´å›å¤
        is_answering = False   # æ˜¯å¦è¿›å…¥å›å¤é˜¶æ®µ
        
        async for chunk in response:
            if not chunk.choices:
                # è¿™é‡Œæ˜¯usageä¿¡æ¯ï¼Œå¯ä»¥è®°å½•ä½†ä¸éœ€è¦å¤„ç†å†…å®¹
                # print(f"Usage: {chunk.usage}")
                continue
                
            delta = chunk.choices[0].delta
            
            # æ”¶é›†æ€è€ƒå†…å®¹
            if hasattr(delta, "reasoning_content") and delta.reasoning_content is not None:
                reasoning_content += delta.reasoning_content
            
            # æ”¶é›†å›å¤å†…å®¹
            if hasattr(delta, "content") and delta.content:
                answer_content += delta.content
        
        # æ£€æŸ¥æ˜¯å¦å› é•¿åº¦é™åˆ¶è€Œæˆªæ–­
        finish_reason = chunk.choices[0].finish_reason if chunk.choices else None
        if finish_reason == "length":
            return reasoning_content, answer_content, "LENGTH_EXCEEDED"
            
        return reasoning_content, answer_content, None

    except RateLimitError:
        print("Rate limit error encountered.")
        return "", "", "RATE_LIMIT"
    except APIConnectionError:
        print("API connection error encountered.")
        return "", "", "CONNECTION_ERROR"
    except APITimeoutError:
        print("API timeout error encountered.")
        return "", "", "TIMEOUT"
    except Exception as e:
        print(f"Unexpected error: {e}")
        return "", "", f"Error: {str(e)}"

async def process_single_problem(sem, client, idx, row):
    async with sem:
        problem_text = row['problem']
        ground_truth = row['answer']
        problem_results = []

        for attempt in range(1, MAX_ATTEMPTS + 1):
            retry_wait = 2
            
            # --- API ç”Ÿæˆ ---
            while True:
                reasoning, answer, error = await get_qwen_response_async(client, problem_text)
                
                if error == "RATE_LIMIT":
                    await asyncio.sleep(retry_wait)
                    retry_wait = min(retry_wait * 2, 60)
                    continue
                elif error in ["CONNECTION_ERROR", "TIMEOUT"]:
                    await asyncio.sleep(5)
                    continue
                elif error:
                    reasoning = f"[API Error] {error}"
                    break
                else:
                    break 

            # --- åˆ¤é¢˜å‡†å¤‡ ---
            judge_input = None
            extracted_boxed = None
            judge_type = "fail"
            
            if not error:
                extracted_boxed = extract_last_boxed_content(answer)
                
                # ã€ç­–ç•¥ã€‘ä¼˜å…ˆ Boxedï¼Œæ²¡æœ‰åˆ™å…¨æ–‡
                if extracted_boxed:
                    judge_input = extracted_boxed
                    judge_type = "boxed"
                else:
                    judge_input = answer 
                    judge_type = "full_text"
            
            # --- æ‰§è¡Œåˆ¤é¢˜ ---
            if judge_input:
                loop = asyncio.get_running_loop()
                is_correct = await loop.run_in_executor(
                    judge_executor, 
                    run_judge_sync, 
                    judge_input,
                    ground_truth
                )
            else:
                is_correct = False

            record = {
                "id": idx,
                "problem": problem_text,
                "ground_truth": ground_truth,
                "attempt": attempt,
                "qwen_reasoning": reasoning,
                "qwen_answer": answer,
                "extracted_boxed": extracted_boxed, 
                "judge_input_type": judge_type,
                "is_correct": is_correct
            }
            problem_results.append(record)

            if is_correct:
                break
        
        return problem_results

async def main():
    # è°ƒæ•´è¿æ¥æ± ä»¥æ”¯æŒ 200+ å¹¶å‘
    limits = httpx.Limits(max_keepalive_connections=MAX_CONCURRENCY + 50, max_connections=MAX_CONCURRENCY + 100)
    http_client = httpx.AsyncClient(limits=limits, timeout=REQUEST_TIMEOUT)
    
    client = AsyncOpenAI(api_key=GEN_API_KEY, base_url=GEN_BASE_URL, http_client=http_client)

    print(f"è¯»å–æ–‡ä»¶: {INPUT_FILE}...")
    try:
        df = pd.read_parquet(INPUT_FILE)
        print(f"æˆåŠŸåŠ è½½ï¼Œå…± {len(df)} æ¡æ•°æ®ã€‚")
    except Exception as e:
        print(f"è¯»å–å¤±è´¥: {e}")
        return

    sem = asyncio.Semaphore(MAX_CONCURRENCY)
    
    print("="*60)
    print(f"ğŸš€ å…¨é€Ÿå¯åŠ¨ | å¹¶å‘: {MAX_CONCURRENCY} | MaxTokens: {MAX_TOKENS}")
    print(f"æ¨¡å¼: æµå¼ + æœ¬åœ°LLM Judge (ä¼˜å…ˆBoxed -> é™çº§FullText)")
    print(f"æ€è€ƒé¢„ç®—: {THINKING_BUDGET}")
    print("="*60)

    tasks = [process_single_problem(sem, client, idx, row) for idx, row in df.iterrows()]
    
    start_time = time.time()
    results_nested = await tqdm_asyncio.gather(*tasks)
    all_results = [item for sublist in results_nested for item in sublist]
    elapsed = time.time() - start_time

    if not all_results: return
    
    # ä¿å­˜ç»“æœ
    df_res = pd.DataFrame(all_results).sort_values(by=['id', 'attempt'])
    
    print(f"æ­£åœ¨ä¿å­˜ ({len(df_res)}æ¡è®°å½•)...")
    df_res.to_excel(OUTPUT_BASE + "_all.xlsx", index=False)
    
    df_correct = df_res[df_res['is_correct'] == True]
    df_correct.to_excel(OUTPUT_BASE + "_correct.xlsx", index=False)
    
    # æœ€ç»ˆç»Ÿè®¡
    uniq_correct = len(df_correct['id'].unique())
    print("-" * 30)
    print(f"è€—æ—¶: {elapsed:.1f}s | åå: {len(df)/elapsed:.2f} TPS")
    print(f"å‡†ç¡®ç‡: {uniq_correct}/{len(df)} ({uniq_correct/len(df):.2%})")

    await http_client.aclose()
    judge_executor.shutdown()

if __name__ == "__main__":
    try:
        import uvloop
        uvloop.install()
    except: 
        pass
    asyncio.run(main())