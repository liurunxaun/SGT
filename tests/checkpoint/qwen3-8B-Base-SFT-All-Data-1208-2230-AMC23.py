import pandas as pd
import os
import sys

# è·¯å¾„è®¾ç½®ï¼šè¯·ç¡®ä¿æ­¤è·¯å¾„åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ˜¯æ­£ç¡®çš„
sys.path.append("/data/home/the/rxliu/projects/open-r1-main/tests/utils")

from concurrent.futures import ThreadPoolExecutor
from openai import OpenAI
from tqdm import tqdm
from llm_judge import llm_judge_via_api
from inference_sglang import inference_sglang
import time as time_module # å¯¼å…¥timeæ¨¡å—ç”¨äºè·å–å½“å‰æ—¶é—´


# ================= å‚æ•°é…ç½® =================

# å¾ªç¯å’Œç»“æœç›®å½•å‚æ•°
REPETITIONS = 3 # <--- æ–°å¢ï¼šé‡å¤æ‰§è¡Œçš„æ¬¡æ•°

# Sglang æ¨ç†å‚æ•°
dataset_name = "AMC23"
dataset_path = "/ssd5/rxliu/datasets/AMC23/data/test-00000-of-00001.parquet"
query_field = "question"
model = "qwen3-8B-Base-SFT-All-Data-1208-2230-checkpoint-105"
temperature = 0.6
max_tokens = 8192
system_prompt = ""

# llm judge é…ç½®
API_KEY = "sk-8d445207b1ab47efb83069ccc1b845b6"
API_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
JUDGE_MODEL = "qwen3-next-80b-a3b-instruct"
client = OpenAI(api_key=API_KEY, base_url=API_URL)
api_workers = 4

# æµ‹è¯•å‚æ•°
answer_field = "answer"


# ================= æ•°æ®å¤„ç†å‡½æ•° (ä¿æŒä¸å˜) =================

def process_ground_truth(text):

    return text


def process_row(row):
    """
    å¤„ç†å•è¡Œæ•°æ®çš„çº¿ç¨‹å‡½æ•°
    """
    # 1. è·å–åŸå§‹æ•°æ®
    pred = row.get('predicted_answer', '')
    raw_gt = row.get('ground_truth', '')
    
    # 2. å¤„ç† Ground Truth
    clean_gt = process_ground_truth(raw_gt)
    
    # 3. è°ƒç”¨ Judge
    # è¿™é‡Œçš„ client å˜é‡æ²¡æœ‰åœ¨å‡½æ•°å†…éƒ¨ä½¿ç”¨ï¼Œä½†ä¸ºäº†ä¸æ‚¨çš„ä»£ç ä¿æŒä¸€è‡´ï¼Œæš‚æ—¶ä¿ç•™
    is_correct = llm_judge_via_api(pred, clean_gt, API_URL, API_KEY, JUDGE_MODEL)
    
    # 4. è¿”å›å®Œæ•´è¡Œæ•°æ®ï¼ˆåŒ…å«åŸæœ‰åˆ—å’Œæ–°ç»“æœï¼‰
    new_row = row.copy()
    new_row['processed_ground_truth'] = clean_gt
    new_row['is_correct_judge'] = is_correct
    return new_row


# ================= ä¸»ç¨‹åº (ä¸»è¦ä¿®æ”¹éƒ¨åˆ†) =================

def main():
    # è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²ç”¨äºæ–‡ä»¶å¤¹å‘½å
    current_time_str = time_module.strftime("%Y%m%d-%H%M%S")
    
    # å®šä¹‰æ ¹è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
    base_output_dir = "/data/home/the/rxliu/projects/open-r1-main/tests/results"
    
    # å®šä¹‰æœ¬æ¬¡æµ‹è¯•çš„ä¸“å±æ–‡ä»¶å¤¹è·¯å¾„
    result_folder = os.path.join(base_output_dir, f"{model}-{dataset_name}-{current_time_str}")
    
    # åˆ›å»ºç»“æœæ–‡ä»¶å¤¹
    os.makedirs(result_folder, exist_ok=True)
    print(f"æ‰€æœ‰ç»“æœå°†ä¿å­˜åœ¨æ–‡ä»¶å¤¹: {result_folder}")

    accuracy_list = []

    for i in range(1, REPETITIONS + 1):
        print(f"\n--- ğŸ§ª å¼€å§‹ç¬¬ {i}/{REPETITIONS} æ¬¡æµ‹è¯• ---")
        
        # 1. å®šä¹‰æœ¬æ¬¡å¾ªç¯çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
        inference_output_path = os.path.join(result_folder, f"inference_run_{i}.xlsx")
        result_output_path = os.path.join(result_folder, f"result_run_{i}.xlsx")
        
        # 2. sglang æ¨ç†
        print(f"å¼€å§‹ç¬¬ {i} æ¬¡ SGLang æ¨ç†...")
        try:
            inference_sglang(dataset_path, system_prompt, query_field, answer_field, inference_output_path, model, temperature, max_tokens)
        except Exception as e:
            print(f"ğŸš¨ ç¬¬ {i} æ¬¡æ¨ç†å¤±è´¥: {e}")
            continue

        # 3. è¯»å–æ¨ç†ç»“æœ
        if not os.path.exists(inference_output_path):
            print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {inference_output_path}ï¼Œè·³è¿‡æœ¬æ¬¡è¯„æµ‹ã€‚")
            continue
            
        print(f"æ­£åœ¨è¯»å– {inference_output_path} ...")
        df = pd.read_excel(inference_output_path)
        
        # 4. LLM Judge è¯„æµ‹
        data_list = df.to_dict('records')
        results = []
        
        print(f"å¼€å§‹å¯¹ {len(data_list)} æ¡æ•°æ®è¿›è¡Œ LLM Judge è¯„æµ‹ (å¹¶å‘æ•°: {api_workers})")
        with ThreadPoolExecutor(max_workers=api_workers) as executor:
            # map æŒ‰é¡ºåºè¿”å›ç»“æœï¼Œtqdm æ˜¾ç¤ºè¿›åº¦æ¡
            results = list(tqdm(executor.map(process_row, data_list), total=len(data_list)))

        # 5. å¤„ç†ç»“æœä¸è®¡ç®—å‡†ç¡®ç‡
        result_df = pd.DataFrame(results)

        num_correct = result_df["is_correct_judge"].sum()
        total = len(result_df)
        accuracy = num_correct / total if total > 0 else 0
        
        accuracy_list.append(accuracy) # å­˜å‚¨æœ¬æ¬¡å‡†ç¡®ç‡
        
        print(f"\nç¬¬ {i} æ¬¡ Judge æ­£ç¡®æ•°é‡ï¼š{num_correct}/{total}")
        print(f"ç¬¬ {i} æ¬¡ Judge å‡†ç¡®ç‡ï¼š{accuracy:.4f}")
        
        # 6. ä¿å­˜æœ¬æ¬¡ç»“æœè‡³æ–‡ä»¶
        result_df.to_excel(result_output_path, index=False)
        print(f"ç¬¬ {i} æ¬¡ç»“æœå·²ä¿å­˜è‡³ {result_output_path}")

    # 7. è®¡ç®—å¹¶ä¿å­˜æœ€ç»ˆå¹³å‡ç»“æœ
    if accuracy_list:
        avg_accuracy = sum(accuracy_list) / len(accuracy_list)
        
        print("\n" + "="*50)
        print(f"ğŸ‰ **æ‰€æœ‰ {len(accuracy_list)} æ¬¡æµ‹è¯•çš„å¹³å‡å‡†ç¡®ç‡ï¼š{avg_accuracy:.4f}**")
        print("="*50)

        # åˆ›å»ºä¸€ä¸ªæ±‡æ€» DataFrame
        summary_data = {
            'Run': [f'Run {j+1}' for j in range(len(accuracy_list))] + ['Average'],
            'Accuracy': [f'{acc:.4f}' for acc in accuracy_list] + [f'{avg_accuracy:.4f}']
        }
        summary_df = pd.DataFrame(summary_data)
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_output_path = os.path.join(result_folder, "summary_average_accuracy.xlsx")
        summary_df.to_excel(summary_output_path, index=False)
        print(f"æ±‡æ€»ç»“æœå·²ä¿å­˜è‡³ {summary_output_path}")
    else:
        print("\nğŸ˜” æ²¡æœ‰æˆåŠŸå®Œæˆçš„æµ‹è¯•è½®æ¬¡ï¼Œæ— æ³•è®¡ç®—å¹³å‡å‡†ç¡®ç‡ã€‚")

if __name__ == "__main__":
    main()